{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "front_img = cv2.imread('front.jpg', cv2.IMREAD_COLOR)\n",
    "left_img = cv2.imread('left.jpg', cv2.IMREAD_COLOR)\n",
    "right_img = cv2.imread('right.jpg', cv2.IMREAD_COLOR)\n",
    "rear_img = cv2.imread('rear.jpg', cv2.IMREAD_COLOR)\n",
    "car_img = cv2.imread('car.png', cv2.IMREAD_COLOR)\n",
    "car_img = cv2.rotate(car_img, cv2.ROTATE_180)\n",
    "print(front_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm 만들기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_src = np.float32([\n",
    "    (125, 180),\n",
    "    (0, 440),\n",
    "    (500, 180),\n",
    "    (640, 440)\n",
    "])\n",
    "\n",
    "forward_dst = np.float32([\n",
    "    (140, 90),\n",
    "    (160, 440),\n",
    "    (480, 85),\n",
    "    (470, 445)\n",
    "])\n",
    "\n",
    "backward_src = np.float32([\n",
    "    (115, 90),\n",
    "    (0, 270),\n",
    "    (530, 95),\n",
    "    (840, 480)\n",
    "])\n",
    "\n",
    "backward_dst = np.float32([\n",
    "    (160, 100),\n",
    "    (150, 370),\n",
    "    (500, 95),\n",
    "    (510, 480)\n",
    "])\n",
    "\n",
    "left_src = np.float32([\n",
    "    (115, 55),\n",
    "    (15, 410),\n",
    "    (520, 30),\n",
    "    (620, 400)\n",
    "])\n",
    "\n",
    "left_dst = np.float32([\n",
    "    (140, 90),\n",
    "    (140, 410),\n",
    "    (480, 85),\n",
    "    (480, 425)\n",
    "])\n",
    "\n",
    "right_src = np.float32([\n",
    "    (100, 45),\n",
    "    (5,415),\n",
    "    (510, 45),\n",
    "    (620, 410)\n",
    "])\n",
    "\n",
    "right_dst = np.float32([\n",
    "    (140, 90),\n",
    "    (140, 440),\n",
    "    (480, 85),\n",
    "    (480, 445)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def front(img):\n",
    "    IMAGE_H, IMAGE_W, _ = img.shape\n",
    "\n",
    "    #print(img.shape)\n",
    "    #img = np.concatenate([np.zeros((400,250,3)).astype(np.uint8),img,np.zeros((400,250,3)).astype(np.uint8)],1)\n",
    "\n",
    "    src = forward_src#np.float32([[249, 399], [549, 399], [289, 0], [509, 0]])\n",
    "    dst = forward_dst#np.float32([[279, 399], [519, 399], [0, 0], [799, 0]])\n",
    "    #src = np.float32([[210,115], [210,180], [150,120], [150,175]])\n",
    "    #dst = np.float32([[210,115], [210,180], [150,115], [150,180]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst) # The transformation matrix\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src) # Inverse transformation\n",
    "\n",
    "    IMAGE_H, IMAGE_W, _ = img.shape\n",
    "\n",
    "    warped_img = cv2.warpPerspective(img, M, (IMAGE_W, IMAGE_H))#[:300] # Image warping\n",
    "    output = warped_img[90:,:-10]\n",
    "    return output#cv2.resize(warped_img[200:,100:-100], dsize=(800, 400),interpolation=cv2.INTER_LINEAR)#warped_img\n",
    "\n",
    "def rear(img):\n",
    "        IMAGE_H, IMAGE_W, _ = img.shape\n",
    "    \n",
    "    \t#img = np.concatenate([np.zeros((400,250,3)).astype(np.uint8),img,np.zeros((400,250,3)).astype(np.uint8)],1)\n",
    "        src = backward_src#np.float32([[249, 399], [549, 399], [289, 0], [509, 0]])\n",
    "        dst = backward_dst#np.float32([[279, 399], [519, 399], [0, 0], [799, 0]])\n",
    "    \t#src = np.float32([[210,115], [210,180], [150,120], [150,175]])\n",
    "        #dst = np.float32([[210,115], [210,180], [150,115], [150,180]])\n",
    "        M = cv2.getPerspectiveTransform(src, dst) # The transformation matrix\n",
    "        Minv = cv2.getPerspectiveTransform(dst, src) # Inverse transformation\n",
    "    \n",
    "        IMAGE_H, IMAGE_W, _ = img.shape\n",
    "    \n",
    "        warped_img = cv2.warpPerspective(img, M, (IMAGE_W, IMAGE_H))#[:300] # Image warping\n",
    "        output = warped_img[90:,:]\n",
    "        output = cv2.rotate(output, cv2.ROTATE_180)\n",
    "        return output#cv2.resize(warped_img[200:,100:-100], dsize=(800, 400),interpolation=cv2.INTER_LINEAR)#warped_img\n",
    "    \n",
    "def side_left(img):\n",
    "    \n",
    "    IMAGE_H, IMAGE_W, _ = img.shape\n",
    "    #src = np.float32([[0, 299], [399, 299], [0, 0], [399, 0]])\n",
    "    #dst = np.float32([[0, 299], [399, 299], [100, 0], [299, 0]])\n",
    "    src = left_src\n",
    "    dst = left_dst\n",
    "    M = cv2.getPerspectiveTransform(src, dst) # The transformation matrix\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src) # Inverse transformation.mkv\n",
    "    \n",
    "    warped_img = cv2.warpPerspective(img, M, (IMAGE_W, IMAGE_H)) # Image warping\n",
    "    output = warped_img[90:,:]\n",
    "    output = cv2.rotate(output, cv2.ROTATE_90_COUNTERCLOCKWISE)#[:,:350]\n",
    "    # warped_img = cv2.warpPerspective(img, M, (IMAGE_H, IMAGE_W)) # Image warping\n",
    "    \n",
    "    return output\n",
    "    \n",
    "def side_right(img):\n",
    "    \n",
    "    IMAGE_H, IMAGE_W, _ = img.shape\n",
    "    \n",
    "    #src = np.float32([[0, 299], [399, 299], [0, 0], [399, 0]])\n",
    "    #dst = np.float32([[0, 299], [399, 299], [100, 0], [299, 0]])\n",
    "    src = right_src\n",
    "    dst = right_dst\n",
    "    M = cv2.getPerspectiveTransform(src, dst) # The transformation matrix\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src) # Inverse transformation.mkv\n",
    "\n",
    "    warped_img = cv2.warpPerspective(img, M, (IMAGE_W, IMAGE_H)) # Image warping\n",
    "    output = warped_img[90:,:]\n",
    "    output = cv2.rotate(output, cv2.ROTATE_90_CLOCKWISE)#[:,:350]\n",
    "    # warped_img = cv2.warpPerspective(img, M, (IMAGE_H, IMAGE_W)) # Image warping\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "(390, 640, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = front_img.copy()\n",
    "print(temp.shape)\n",
    "# cv2.line(temp,(510, 45), (620, 410), (0,0,255), 3)\n",
    "temp = front(temp)\n",
    "print(temp.shape)\n",
    "cv2.imwrite('temp.png', temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = front(front_img)\n",
    "# print(front_img.shape)\n",
    "IMAGE_H, IMAGE_W, _ = front_img.shape\n",
    "car = np.zeros((IMAGE_H, IMAGE_W, 3), np.uint8)\n",
    "# car[:,150:490,:] = car_img\n",
    "# print(car.shape)\n",
    "# print(front_img.shape)\n",
    "temp_front = front_img.copy()\n",
    "temp_rear = rear_img.copy()\n",
    "# temp_rear = cv2.rotate(temp_rear, cv2.ROTATE_180)\n",
    "trans_front = front(temp_front)\n",
    "trans_rear = rear(temp_rear)\n",
    "\n",
    "x = np.vstack([trans_front, car, trans_rear])\n",
    "cv2.imwrite('test.png', x)\n",
    "# y = np.vstack([front_img, car, cv2.rotate(rear_img, cv2.ROTATE_180)])\n",
    "# cv2.imwrite('test2.png', y)\n",
    "# test2 = rear(test)\n",
    "# cv2.imwrite('test2.png', test2)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge(head,tail,left,right,car):\n",
    "    # horizontal = np.concatenate([np.zeros((640,179,3)),left,np.zeros((640,236,3)),right,np.zeros((640,179,3))],1)\n",
    "    car_width = 650\n",
    "    car_height = 640+170\n",
    "    car_final = cv2.resize(car, (car_width, car_height), interpolation=cv2.INTER_LINEAR)\n",
    "    side_H, side_W, _ = left.shape\n",
    "    head_H, head_W, _ = head.shape\n",
    "    total_width = car_width+side_W+side_W\n",
    "    \n",
    "    horizontal = np.concatenate([left,np.zeros((side_H,car_width,3)),right],1)\n",
    "    horizontal = cv2.resize(horizontal, dsize=(horizontal.shape[1],800), interpolation = cv2.INTER_LINEAR)\n",
    "    tail = cv2.resize(tail, dsize=(total_width,600), interpolation = cv2.INTER_LINEAR)\n",
    "    head = cv2.resize(head, dsize=(total_width,600), interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    #head = head/255#np.concatenate([np.zeros((400,(800-500)//2,3)),head/255,np.zeros((400,(800-500)//2,3))],1)\n",
    "    \n",
    "    # head_empty = np.zeros((140,head.shape[1],3)).astype(np.uint8)\n",
    "    # tail_empty = np.zeros((140,tail.shape[1],3)).astype(np.uint8)\n",
    "    # bev = np.concatenate([head,head_empty,horizontal,tail_empty,tail],0)\n",
    "    bev = np.concatenate([head, horizontal, tail], 0)\n",
    "    bev[head.shape[0]-25:head.shape[0]+car_height-25,side_W:side_W+car_width,:] = car_final\n",
    "    bev = (bev).astype(np.uint8)\n",
    "    # tt = np.zeros((3300, 1600))\n",
    "    #bev = Image.fromarray(bev)\n",
    "\n",
    "    return bev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff = front(front_img)\n",
    "rr = rear(rear_img)\n",
    "ls = side_left(left_img)\n",
    "rs = side_right(right_img)\n",
    "# IMAGE_H, IMAGE_W, _ = front_img.shape\n",
    "# car = np.zeros((IMAGE_H, IMAGE_W, 3), np.uint8)\n",
    "# car[:,150:490,:] = car_img\n",
    "\n",
    "x = merge(ff, rr, ls, rs, car_img)\n",
    "# x = cv2.line(left_img.copy(), (0, 0), (399, 0), (0,0,255),3)\n",
    "# print(sero)\n",
    "\n",
    "# x[sero:-sero,(240+179):-(240+179)] = car_img\n",
    "cv2.imwrite('x.png', x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lane detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv(img, color='green'):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # 휴리스틱으로 구한거 같은데? 오진다,\n",
    "    if color == 'green':\n",
    "        mask = cv2.inRange(hsv, (25, 60, 50), (86, 255, 255))\n",
    "    elif color == 'red':\n",
    "        mask = cv2.inRange(hsv, (115, 100, 50), (130, 255, 255))\n",
    "    elif color == 'blue':\n",
    "        mask = cv2.inRange(hsv, (10, 150, 50), (30, 255, 255))\n",
    "    elif color == 'yellow':\n",
    "        mask = cv2.inRange(hsv, (80, 40, 145), (150, 255, 255))\n",
    "        # mask = cv2.inRange(hsv, (80, 100, 145), (150, 255, 255))\n",
    "\n",
    "    imask = mask > 0\n",
    "    output = np.zeros_like(hsv, np.uint8)\n",
    "    output[imask] = 255\n",
    "\n",
    "    return output[:,:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_square(input):\n",
    "    min_area = 740\n",
    "    H, W = input.shape[:2]\n",
    "    # image morpholgy로 라인만 찾는거 같음\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9)) # kernel 만들기\n",
    "    clean = cv2.morphologyEx(input, cv2.MORPH_OPEN, kernel) # 이럴거면 왜 이미지 하나로 opening, closing하는지?\n",
    "    # kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15,15))\n",
    "    # clean = cv2.morphologyEx(input, cv2.MORPH_CLOSE, kernel)\n",
    "    cv2.imwrite('test.png', clean)\n",
    "    contours = cv2.findContours(clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) #RETR_EXTERNAL: 외각선만 찾기, CHAIN_APPROX_SIMPLE: 수직선, 수평선, 대각선에 대해 끝점만 저장\n",
    "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "    square = None\n",
    "    square_center = 0\n",
    "    is_square = False\n",
    "\n",
    "    for c in contours:\n",
    "        rot_rect = cv2.minAreaRect(c) # contour를 둘러싸는 최소한 크기의 직사각형 만들기\n",
    "        temp_area = rot_rect[1][0] * rot_rect[1][1]\n",
    "        temp_square = cv2.boxPoints(rot_rect)\n",
    "        temp_center = np.int0(np.mean(temp_square, axis=0))\n",
    "\n",
    "        if temp_area >= min_area and temp_center[0] > square_center:\n",
    "            square = np.int0(temp_square)\n",
    "            square_center = temp_center[0]\n",
    "            area = temp_area\n",
    "            is_square = True\n",
    "\n",
    "    return square, is_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_view = hsv(front_img, 'yellow')\n",
    "front_view,_ = detect_square(front_view)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 480 is out of bounds for axis 0 with size 480",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4957/3959319908.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfront_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfront_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m480\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 480 is out of bounds for axis 0 with size 480"
     ]
    }
   ],
   "source": [
    "np.zeros((3,2))\n",
    "front_img.shape\n",
    "front_img[480,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv(img, color='green'):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # 휴리스틱으로 구한거 같은데? 오진다,\n",
    "    if color == 'green':\n",
    "        mask = cv2.inRange(hsv, (25, 60, 50), (86, 255, 255))\n",
    "    elif color == 'red':\n",
    "        mask = cv2.inRange(hsv, (115, 100, 50), (130, 255, 255))\n",
    "    elif color == 'blue':\n",
    "        mask = cv2.inRange(hsv, (10, 150, 50), (30, 255, 255))\n",
    "    elif color == 'yellow':\n",
    "        mask = cv2.inRange(hsv, (80, 40, 145), (150, 255, 255))\n",
    "        # mask = cv2.inRange(hsv, (80, 100, 145), (150, 255, 255))\n",
    "\n",
    "    imask = mask > 0\n",
    "    output = np.zeros_like(hsv, np.uint8)\n",
    "    output[imask] = 255\n",
    "\n",
    "    return output[:,:,0]\n",
    "\n",
    "def clean(img):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9)) # kernel 만들기\n",
    "    clean = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel) # 이럴거면 왜 이미지 하나로 opening, closing하는지?\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15,15))\n",
    "    output = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "    # cv2.imwrite('test.png', clean)\n",
    "    return output\n",
    "\n",
    "def fit_poly(img_shape, leftx, lefty, rightx, righty):\n",
    "    ### TO-DO: Fit a second order polynomial to each with np.polyfit() ###\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    ### TO-DO: Calc both polynomials using ploty, left_fit and right_fit ###\n",
    "    left_fitx = left_fit[0] * (ploty ** 2) + left_fit[1] * ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0] * (ploty ** 2) + right_fit[1] * ploty + right_fit[2]\n",
    "    \n",
    "    return left_fitx, right_fitx, ploty, left_fit, right_fit\n",
    "\n",
    "def search_around_poly(binary_warped, left_fit, right_fit):\n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    margin = 10\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    ### TO-DO: Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    ### Hint: consider the window areas for the similarly named variables ###\n",
    "    ### in the previous quiz, but change the windows to our new search area ###\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin))\n",
    "                      & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) \n",
    "                       & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit new polynomials\n",
    "    left_fitx, right_fitx, ploty, left_fit_refined, right_fit_refined = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [0, 0, 255]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    result = cv2.fillPoly(window_img.copy(), np.int_([left_line_pts]), (0,255,0))\n",
    "    nonzero_final_left = result.nonzero()\n",
    "    ly = np.array(nonzero_final_left[0])\n",
    "    lx = np.array(nonzero_final_left[1])\n",
    "    result = cv2.fillPoly(window_img.copy(), np.int_([right_line_pts]), (0,255,0))\n",
    "    nonzero_final_right = result.nonzero()\n",
    "    ry = np.array(nonzero_final_right[0])\n",
    "    rx = np.array(nonzero_final_right[1])\n",
    "    # result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    # cv2.imwrite('xxx.png', result)\n",
    "    # Plot the polynomial lines onto the image\n",
    "    # plt.plot(left_fitx, ploty, color='yellow')\n",
    "    # plt.plot(right_fitx, ploty, color='yellow')\n",
    "    ## End visualization steps ##\n",
    "    \n",
    "    # return result, left_fit_refined, right_fit_refined, left_fitx, right_fitx, ploty\n",
    "    # ly = nonzeroy[left_lane_inds]\n",
    "    # lx = nonzerox[left_lane_inds]\n",
    "    # ry = nonzeroy[right_lane_inds]\n",
    "    # rx = nonzerox[right_lane_inds]\n",
    "    return result, ly, lx, ry, rx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lane_detect(img):\n",
    "    img_ori = img\n",
    "    img_hsv = hsv(img, color = 'yellow')\n",
    "    img_clean = clean(img_hsv)\n",
    "    out_img = cv2.cvtColor(img_clean, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 10\n",
    "\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 50\n",
    "\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int64(img_clean.shape[0]//nwindows)\n",
    "\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(img_clean[img_clean.shape[0]-window_height:img_clean.shape[0],:], axis=0)\n",
    "\n",
    "\n",
    "    midpoint = np.int64(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    nonzero = img_clean.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    # for window in range(nwindows):\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = img_clean.shape[0] - (window+1)*window_height\n",
    "        win_y_high = img_clean.shape[0] - window*window_height\n",
    "        ### TO-DO: Find the four below boundaries of the window ###\n",
    "        win_xleft_low = leftx_current - margin  # Update this\n",
    "        win_xleft_high = leftx_current + margin  # Update this\n",
    "        win_xright_low = rightx_current - margin  # Update this\n",
    "        win_xright_high = rightx_current + margin  # Update this\n",
    "\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low, win_y_low),(win_xleft_high, win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # plt.imshow(xx)\n",
    "        ### TO-DO: Identify the nonzero pixels in x and y within the window ###\n",
    "        good_left_inds = ((nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high) & (nonzeroy >= win_y_low) & (nonzeroy < win_y_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzerox >= win_xright_low) & (nonzerox < win_xright_high) & (nonzeroy >= win_y_low) & (nonzeroy < win_y_high)).nonzero()[0]\n",
    "\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "\n",
    "        ### TO-DO: If you found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their peak histogram ###\n",
    "        if(len(good_left_inds) > minpix):\n",
    "            leftx_current = np.int64(np.mean(nonzerox[good_left_inds]))\n",
    "        if(len(good_right_inds) > minpix):\n",
    "            rightx_current = np.int64(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "        # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    ### TO-DO: Fit a second order polynomial to each using `np.polyfit` ###\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "\n",
    "    ploty = np.linspace(0, img_clean.shape[0]-1, img_clean.shape[0] )\n",
    "    # plot\n",
    "    print(ploty)\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    lane, ly, lx, ry, rx = search_around_poly(img_clean, left_fit, right_fit)\n",
    "    img_ori[ly, lx] = (0, 0, 255)\n",
    "    img_ori[ry, rx] = (0, 0, 255)\n",
    "    output = img_ori\n",
    "    return output, lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"x.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000e+00 1.000e+00 2.000e+00 ... 1.997e+03 1.998e+03 1.999e+03]\n"
     ]
    }
   ],
   "source": [
    "x, _ = lane_detect(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z = x+img\n",
    "cv2.imwrite('xx.png',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
